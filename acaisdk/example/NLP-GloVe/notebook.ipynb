{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ee5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.realpath('__file__')) + '/../../../')\n",
    "from acaisdk.file import File\n",
    "from acaisdk.project import Project\n",
    "from acaisdk.fileset import FileSet\n",
    "from acaisdk.job import Job\n",
    "from acaisdk.meta import *\n",
    "from acaisdk.utils import utils\n",
    "from acaisdk import credentials\n",
    "# from acaisdk import automl\n",
    "\n",
    "utils.DEBUG = True  # print debug messages\n",
    "workspace = os.path.dirname(os.path.realpath('__file__'))  # get current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3764342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up project\n",
    "# \n",
    "# Either:\n",
    "# 1) Provide your existing token for some project\n",
    "# 2) Fill in information for new project creation (project_name, project_admin, project_user, optional [csp, budget])\n",
    "# Do not change root_token!\n",
    "token = ''\n",
    "force = False\n",
    "    \n",
    "project_name = ''\n",
    "project_admin = ''\n",
    "project_user = ''\n",
    "csp = 'AZURE' # AWS/AZURE/GCP/PRIVATE\n",
    "budget = 10 # Default, I have no idea what other options there are\n",
    "\n",
    "try:\n",
    "    p\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    if not force:\n",
    "        if token == '':\n",
    "            print(\"User token {} already exists, saving to variable 'token'. If you want to enforce new project, set 'force=true'.\".format(p['user_token']))\n",
    "            token = p['user_token']\n",
    "    else:\n",
    "        print(\"User token {} already exists but forcing new project.\".format(p['user_token']))\n",
    "\n",
    "\n",
    "if token != '':\n",
    "    print(\"Logging in with existing credentials.\")\n",
    "    credentials.login(token)\n",
    "else:\n",
    "    print(\"Creating new project.\")\n",
    "    if project_name == '' or project_admin == '' or project_user == '':\n",
    "        raise ValueError(\"Some of the 'project_name', 'project_admin', 'project_user' not provided!\")\n",
    "    \n",
    "    root_token = 'EmDlCTBF1ppONSciYVd03M9xkmF6hFqW' \n",
    "    p = Project.create_project(project_name, root_token, project_admin, csp=csp, budget=budget)\n",
    "    p = Project.create_user(project_name, p['project_admin_token'], project_user)\n",
    "    token = p['user_token']\n",
    "    print(\"New user token {}, saved to variable 'token'\".format(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set env variable needed for Phoebe\n",
    "USE_PHOEBE = False\n",
    "if USE_PHOEBE:\n",
    "    os.environ[\"CLUSTER\"] = 'PHOEBE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb522e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command must live in its own cell because chaining with another command trunctuates its output\n",
    "File.list_dir('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686aed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = os.path.join(workspace, 'outputs/')\n",
    "if not os.path.isdir(outputs):\n",
    "    os.mkdir(outputs)\n",
    "inputs = os.path.join(workspace, 'inputs/')\n",
    "if not os.path.isdir(inputs):\n",
    "    os.mkdir(inputs)\n",
    "inf = [f for f in os.listdir(inputs) if os.path.isfile(os.path.join(inputs, f))]\n",
    "print(inf)\n",
    "\n",
    "if inf == []:\n",
    "    raise FileNotFoundError(\"Data is not extracted in the inputs directory! Extract the data NLP-GloVe/fake-and-real-news-dataset.zip NLP-GloVe/glove-twitter.zip to inputs directory (e.g. tar -xvf glove-twitter.zip -C inputs)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ce3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case dataset is not downloaded at all = NLP-GloVe/fake-and-real-news-dataset.zip NLP-GloVe/glove-twitter.zip\n",
    "# not present do the following:\n",
    "#\n",
    "# Install kaggle (pip3 or pip)\n",
    "# pip3 install kaggle\n",
    "#\n",
    "# Download dataset to the workdir of Sentiment-IMDB\n",
    "# kaggle datasets download clmentbisaillon/fake-and-real-news-dataset\n",
    "# kaggle datasets download icw123/glove-twitter\n",
    "#\n",
    "# Untar downloaded dataset to inputs dir\n",
    "# tar -xvf clmentbisaillon/fake-and-real-news-dataset.zip -C inputs\n",
    "# tar -xvf icw123/glove-twitter -C inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4267c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "File.convert_to_file_mapping([inputs], '/nlp-inputs/') \\\n",
    "    .files_to_upload \\\n",
    "    .upload() \\\n",
    "    .as_new_file_set('nlpglove.inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fee0e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "File.list_dir('/nlp-inputs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4805c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload code\n",
    "code = os.path.join(workspace, 'nlp-code.zip')\n",
    "File.upload({code: 'nlp-code.zip'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dba87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "File.list_dir('/nlp-code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16287b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job setting was OOM with 3Gi, 10Gi\n",
    "# I went ahead with LARGE resources, I don't know how much was actually used\n",
    "\n",
    "job_setting = {\n",
    "    \"v_cpu\": \"30\",\n",
    "    \"memory\": \"100Gi\",\n",
    "    \"gpu\": \"0\",\n",
    "    \"command\": \"mkdir -p ./nlp-output/ && (pip install -r requirements.txt) && (python3 nlp.py ./nlp-inputs/ ./nlp-output/ glove.twitter.27B.100d.txt)\",\n",
    "    \"container_image\": \"python:3.10.9\",\n",
    "    'input_file_set': 'nlpglove.inputs',\n",
    "    'output_path': './nlp-output/',\n",
    "    'code': 'nlp-code.zip:7',\n",
    "    'description': 'NLP using GloVe Embeddings',\n",
    "    'name': 'nlp-zipcode-tf-more-mem'\n",
    "}\n",
    "\n",
    "j = Job().with_attributes(job_setting).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08fe757",
   "metadata": {},
   "outputs": [],
   "source": [
    "j.check_job_status(3286)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78453d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from acaisdk.job import Job, JobStatus\n",
    "status = j.wait()\n",
    "if status == JobStatus.FINISHED:\n",
    "    output_file_set = j.output_file_set\n",
    "    print(\"Job done. output file set id:\", output_file_set)\n",
    "else:\n",
    "    print(\"Job went wrong:\", status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bf7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "File.list_dir('/nlp-output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2cd9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "File.download({'/nlp-output/accuracy.txt': outputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee33a24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
